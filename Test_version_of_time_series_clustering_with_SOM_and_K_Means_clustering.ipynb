{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test_version of time series clustering with SOM and K-Means clustering",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMlE9oYZnTDXDBxZ8gL363j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mwithgod3952/jh_Minor_Projects/blob/main/Test_version_of_time_series_clustering_with_SOM_and_K_Means_clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sBr2efLYBqs"
      },
      "source": [
        "#### ***What is clustering ?***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RPz3HswTqql"
      },
      "source": [
        "    - 'Clustering'은 비지도 학습 문제이며, 이를 해결하기 위한 방책이며, \n",
        "    각 데이터 포인트들 간의 '*** 유사도'에 측정 및 이에 기반하여 다수의 데이터 시리즈를 n개의 데이터 그룹으로서 분류시는 것이 학습의 목적이라 할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcGvux2uTK7G"
      },
      "source": [
        "#### ***What is time series ?***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-1ZMlAjcg91"
      },
      "source": [
        "    - Time seriese 데이터는 통상 시간역의 변화에 따른 정형데이터를 다루는데, x축의 Time domain 에 따라 해당 y값의 변화를 다룬다. \n",
        "\n",
        "    일반의 정형데이터와는 구분되며, 이는 시간의 변화에 따른 분산의 변화이다. 이 때문에 'Classification 문제를 풀고자 할 때 분산의 변화를 고려해야 하는데, 이를 위한 전통적인 방법 중 하나가 DTW(Dynamic Time Wrapping)이다. \n",
        "    엄밀히 말하면, 근본적으로는 DWT가 분산을 고려한다고 볼 수는 없다. DTW는 단지 데이터의 패턴을 고려한 각 데이터 포인트 간 '거리'에 기반하기 때문이다.\n",
        "\n",
        "    그렇더라도 데이터의 특정 패턴이 분산의 변화를 반영한다는 점에서 제법 유용한 해결방책이라 볼 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbolytDJ8Xn9"
      },
      "source": [
        "# !pip install MiniSom"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6zKD3cJ8m9X",
        "outputId": "f806c7e8-07aa-43d2-9621-6c5e0c8a26fc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wr-2KTr2qnJj"
      },
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# Algorithms\n",
        "from minisom import MiniSom\n",
        "from tslearn.barycenters import dtw_barycenter_averaging\n",
        "from tslearn.clustering import TimeSeriesKMeans\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLS3bGolr4hJ",
        "outputId": "33a34117-650d-4325-f18e-21e72cd782a7"
      },
      "source": [
        "local_path = '/content/drive/MyDrive/archive'\n",
        "path_names = glob.glob(local_path + \"/*.csv\")\n",
        "\n",
        "multiple_df_ratail = [pd.read_csv(x) for x in path_names]\n",
        "\n",
        "print(\"number of files\", np.shape(path_names)) \n",
        "print(\"number of files in list saved\", np.shape(multiple_df_ratail))"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of files (23,)\n",
            "number of files in list saved (23,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrRgwiTF84gw"
      },
      "source": [
        "mySeries = []\n",
        "for df in multiple_df_ratail:\n",
        "    df.set_index(\"date\", inplace=True)\n",
        "    df.sort_index(inplace=True)\n",
        "    df = df.loc[:,'value']\n",
        "    mySeries.append(df)\n",
        "\n",
        "namesofMySeries = [path_names[x].split('/')[-1][:-4]for x in range(len(path_names))]"
      ],
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJmvGstyM_Oy",
        "outputId": "7e1d484e-d470-449a-a9bd-3fccfc0357ca"
      },
      "source": [
        "def vis_dfs_structure():\n",
        "    num = 0\n",
        "    sd, ed = [],[]\n",
        "\n",
        "    print(\"=\" * 55)\n",
        "    for series in mySeries:\n",
        "        if num < 10:\n",
        "            number = str(f'0{num}')\n",
        "        else:\n",
        "            number = num        \n",
        "\n",
        "        print(f\"[{number}]\", \"start_date: \", series.index[0], \",  \", \"end_date: \",series.index[-1])\n",
        "        sd.append(series.index[0])\n",
        "        ed.append(series.index[-1])\n",
        "        num = num + 1\n",
        "\n",
        "    print(\"=\" * 55)\n",
        "    print(\"\")\n",
        "    print(\"unique values of start date\", set(sd))\n",
        "    print(\"unique values of end date\", set(ed)  )\n",
        "    \n",
        "vis_dfs_structure()    "
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=======================================================\n",
            "[00] start_date:  1992-01-01 ,   end_date:  2019-09-01\n",
            "[01] start_date:  1992-02-01 ,   end_date:  2019-09-01\n",
            "[02] start_date:  1992-01-01 ,   end_date:  2019-09-01\n",
            "[03] start_date:  1992-02-01 ,   end_date:  2019-09-01\n",
            "[04] start_date:  1992-01-01 ,   end_date:  2019-09-01\n",
            "[05] start_date:  1992-01-01 ,   end_date:  2019-09-01\n",
            "[06] start_date:  1992-01-01 ,   end_date:  2019-09-01\n",
            "[07] start_date:  1992-01-01 ,   end_date:  2019-09-01\n",
            "[08] start_date:  1992-01-01 ,   end_date:  2019-09-01\n",
            "[09] start_date:  1992-01-01 ,   end_date:  2019-09-01\n",
            "[10] start_date:  1992-01-01 ,   end_date:  2019-09-01\n",
            "[11] start_date:  1992-01-01 ,   end_date:  2019-09-01\n",
            "[12] start_date:  1992-01-01 ,   end_date:  2019-09-01\n",
            "[13] start_date:  1992-01-01 ,   end_date:  2019-09-01\n",
            "[14] start_date:  1992-01-01 ,   end_date:  2019-09-01\n",
            "[15] start_date:  1992-01-01 ,   end_date:  2019-09-01\n",
            "[16] start_date:  1992-01-01 ,   end_date:  2019-09-01\n",
            "[17] start_date:  1992-02-01 ,   end_date:  2019-09-01\n",
            "[18] start_date:  1992-01-01 ,   end_date:  2019-09-01\n",
            "[19] start_date:  1992-01-01 ,   end_date:  2019-09-01\n",
            "[20] start_date:  1992-01-01 ,   end_date:  2019-09-01\n",
            "[21] start_date:  1992-01-01 ,   end_date:  2019-09-01\n",
            "[22] start_date:  1992-01-01 ,   end_date:  2019-09-01\n",
            "=======================================================\n",
            "\n",
            "unique values of start date {'1992-01-01', '1992-02-01'}\n",
            "unique values of end date {'2019-09-01'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4itUgHaTh1x",
        "outputId": "b13e9460-1593-48af-c66c-45d8b71a2a8b"
      },
      "source": [
        "indices = [i for i, x in enumerate(sd) if x == \"1992-02-01\"]\n",
        "print(\"행의 길이가 다른 리스트 내 데이터프레임의 인덱스 : \", indices)"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "행의 길이가 다른 리스트 내 데이터프레임의 인덱스 :  [1, 3, 17]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hoo74HSXp1uS",
        "outputId": "69b1f7aa-5340-4c3e-f1c6-43d501df0ea8"
      },
      "source": [
        "print(\"check null in all dataframe : \", sum([sum(x.isnull()) for x in mySeries]))"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "check null in all dataframe :  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYOBD_RxslWT"
      },
      "source": [
        "longest_df = mySeries[0].copy()\n",
        "for df_idx in indices:\n",
        "    mySeries[df_idx] = mySeries[df_idx].reindex(longest_df.index)\n",
        "    mySeries[df_idx].interpolate(limit_direction=\"both\",inplace=True)"
      ],
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jj7x_b-8tyN3",
        "outputId": "e0a01bc1-666c-414d-9663-6d42346f5c86"
      },
      "source": [
        "vis_dfs_structure() "
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=======================================================\n",
            "[00] start_date:  1992-01-01 ,   end_date:  2019-09-01\n",
            "[01] start_date:  1992-01-01 ,   end_date:  2019-09-01\n",
            "[02] start_date:  1992-01-01 ,   end_date:  2019-09-01\n",
            "[03] start_date:  1992-01-01 ,   end_date:  2019-09-01\n",
            "[04] start_date:  1992-01-01 ,   end_date:  2019-09-01\n",
            "[05] start_date:  1992-01-01 ,   end_date:  2019-09-01\n",
            "[06] start_date:  1992-01-01 ,   end_date:  2019-09-01\n",
            "[07] start_date:  1992-01-01 ,   end_date:  2019-09-01\n",
            "[08] start_date:  1992-01-01 ,   end_date:  2019-09-01\n",
            "[09] start_date:  1992-01-01 ,   end_date:  2019-09-01\n",
            "[10] start_date:  1992-01-01 ,   end_date:  2019-09-01\n",
            "[11] start_date:  1992-01-01 ,   end_date:  2019-09-01\n",
            "[12] start_date:  1992-01-01 ,   end_date:  2019-09-01\n",
            "[13] start_date:  1992-01-01 ,   end_date:  2019-09-01\n",
            "[14] start_date:  1992-01-01 ,   end_date:  2019-09-01\n",
            "[15] start_date:  1992-01-01 ,   end_date:  2019-09-01\n",
            "[16] start_date:  1992-01-01 ,   end_date:  2019-09-01\n",
            "[17] start_date:  1992-01-01 ,   end_date:  2019-09-01\n",
            "[18] start_date:  1992-01-01 ,   end_date:  2019-09-01\n",
            "[19] start_date:  1992-01-01 ,   end_date:  2019-09-01\n",
            "[20] start_date:  1992-01-01 ,   end_date:  2019-09-01\n",
            "[21] start_date:  1992-01-01 ,   end_date:  2019-09-01\n",
            "[22] start_date:  1992-01-01 ,   end_date:  2019-09-01\n",
            "=======================================================\n",
            "\n",
            "unique values of start date {'1992-01-01'}\n",
            "unique values of end date {'2019-09-01'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "He70X8Ru9Vj1"
      },
      "source": [
        "***scaling between 0 and 1***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qGV-GkZD9Vh"
      },
      "source": [
        "myScaler = MinMaxScaler()\n",
        "mySeries_scaled = []\n",
        "\n",
        "for sr in mySeries:\n",
        "    sr = sr.to_frame()\n",
        "    sr['value'] = sum(myScaler.fit_transform(sr).tolist(), [])\n",
        "    \n",
        "    mySeries_scaled.append(sr)"
      ],
      "execution_count": 262,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fekGhkPsynu9"
      },
      "source": [
        "##### ***1) 자기조직화지도_SOM(Self-Organizing Map) 적용***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-zJ_2x1_tGS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}